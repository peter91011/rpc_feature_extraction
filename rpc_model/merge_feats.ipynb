{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,timedelta\n",
    "from itertools import chain\n",
    "import os\n",
    "os.chdir('/home/y0c07y1/rpc_feature_extraction/rpc_model')\n",
    "import tqdm\n",
    "import glob\n",
    "import gcsfs\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('*.{}'.format('csv'))\n",
    "# files.sort()\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-01-28'\n",
    "gcp_directory = 'gs://msc_fair_airflow/rpc_model/'+start_date+'/'\n",
    "ref_dates = []\n",
    "for x in range(0, 5):\n",
    "    ref_dates.append(str(datetime.strptime(start_date, '%Y-%m-%d').date() - timedelta(days=7)*x))\n",
    "# ref_dates.append(str(datetime.strptime(start_date, '%Y-%m-%d').date() + timedelta(days=7)))\n",
    "\n",
    "gcp_directoty_individual = 'gs://msc_fair_airflow/rpc_model/'+start_date+'/sample_data_individual_feat/'\n",
    "files = extract_gcs_files(gcp_directoty_individual)\n",
    "\n",
    "gcp_directoty_individual = 'gs://msc_fair_airflow/rpc_model/'+start_date+'/sample_data_individual_feat_clickbase/'\n",
    "gcp_directoty_full = 'gs://msc_fair_airflow/rpc_model/'+start_date+'/sample_data_full_feat_clickbase/'\n",
    "\n",
    "files+=extract_gcs_files(gcp_directoty_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on date 2023-01-28\n",
      "header table:  gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_l_2023-01-28.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c0_2023-01-28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c1_2023-01-28.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c2_2023-01-28.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c3_2023-01-28.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c4_2023-01-28.csv\n",
      "merge catalog features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0,2,3,4,5,6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge site features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2023-01-21\n",
      "header table:  gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_l_2023-01-21.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c0_2023-01-21.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c1_2023-01-21.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c2_2023-01-21.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c3_2023-01-21.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c4_2023-01-21.csv\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2023-01-14\n",
      "header table:  gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_l_2023-01-14.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c0_2023-01-14.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c1_2023-01-14.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c2_2023-01-14.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c3_2023-01-14.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c4_2023-01-14.csv\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2023-01-07\n",
      "header table:  gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_l_2023-01-07.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c0_2023-01-07.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c1_2023-01-07.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c2_2023-01-07.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c3_2023-01-07.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c4_2023-01-07.csv\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2022-12-31\n",
      "header table:  gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_l_2022-12-31.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c0_2022-12-31.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c1_2022-12-31.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c2_2022-12-31.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c3_2022-12-31.csv\n",
      "merging file name: gs://msc_fair_airflow/rpc_model/2023-01-28/sample_data_individual_feat_clickbase/semcoop_c4_2022-12-31.csv\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n"
     ]
    }
   ],
   "source": [
    "for date in ref_dates:\n",
    "    print('working on date '+date)\n",
    "    # read header\n",
    "    file = [x for x in files if x[-14:-4] == date and '_l_' in x and 'clickbase' in x][0]\n",
    "    print('header table: ', file)\n",
    "    df_feat_all = pd.read_csv(file)\n",
    "    \n",
    "    df_feat_all = df_feat_all[(~pd.isnull(df_feat_all['catalog_item_id']))&(~pd.isnull(df_feat_all['seller_id']))]\n",
    "    df_feat_all['catalog_item_id'] = df_feat_all['catalog_item_id'].astype('int')\n",
    "    df_feat_all['catalog_item_id'] = df_feat_all['catalog_item_id'].astype('str')\n",
    "    df_feat_all['seller_id'] = df_feat_all['seller_id'].astype('int')\n",
    "    df_feat_all['seller_id'] = df_feat_all['seller_id'].astype('str')\n",
    "    df_feat_all.drop_duplicates(subset = ['adid','is_mobile','source_id'], inplace=True)\n",
    "    \n",
    "    # drop off duplicates catalog_item_id, seller_id\n",
    "    \n",
    "#     # read targets\n",
    "#     file = 'sem_l_'+date+'.csv'\n",
    "#     df_tmp = pd.read_csv(file, index_col=0)\n",
    "#     df_feat_all = df_tmp.merge(df_feat_all, left_on = 'catalog_item_id', right_on = 'catalog_item_id', how='left')\n",
    "    \n",
    "    # read sem coop features\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'semcoop' in x and x[-17]=='c']\n",
    "    \n",
    "    # left join to ensure item coverage is based on target coverage\n",
    "    for file in files_to_read:\n",
    "        print('merging file name:', file)\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['adid','is_mobile','source_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id', 'source_id', 'adid', 'is_mobile'], how='left')\n",
    "        del df_tmp\n",
    "        \n",
    "    # read catalog feature\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'catalog' in x]\n",
    "    for file in files_to_read:\n",
    "        print('merge catalog features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['catalog_item_id','seller_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id'], how='left')\n",
    "        del df_tmp\n",
    "        \n",
    "    # read site features\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'site' in x]\n",
    "    for file in files_to_read:\n",
    "        print('merge site features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['catalog_item_id','seller_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id'], how='left')\n",
    "        del df_tmp\n",
    "        \n",
    "    # read bounce features\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'bounce' in x]\n",
    "    for file in files_to_read:\n",
    "        print('merge bounce features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['catalog_item_id','seller_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id'], how='left')\n",
    "        del df_tmp\n",
    "\n",
    "    upload_csv_to_cloud_storage(df_feat_all, gcp_directoty_full+'df_feat_all_coop_item_'+date+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on date 2023-01-28\n",
      "merge sem coop features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge catalog features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0,2,3,4,5,6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2023-01-21\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2023-01-14\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2023-01-07\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n",
      "working on date 2022-12-31\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge sem coop features\n",
      "merge catalog features\n",
      "merge site features\n",
      "merge site features\n",
      "merge bounce features\n",
      "merge bounce features\n"
     ]
    }
   ],
   "source": [
    "for date in ref_dates:\n",
    "    print('working on date '+date)\n",
    "    # read header\n",
    "    file = [x for x in files if x[-14:-4] == date and 'header' in x][0]\n",
    "    df_feat_all = pd.read_csv(file)\n",
    "    \n",
    "    df_feat_all = df_feat_all[(~pd.isnull(df_feat_all['catalog_item_id']))&(~pd.isnull(df_feat_all['seller_id']))]\n",
    "    df_feat_all['catalog_item_id'] = df_feat_all['catalog_item_id'].astype('int')\n",
    "    df_feat_all['catalog_item_id'] = df_feat_all['catalog_item_id'].astype('str')\n",
    "    df_feat_all['seller_id'] = df_feat_all['seller_id'].astype('int')\n",
    "    df_feat_all['seller_id'] = df_feat_all['seller_id'].astype('str')\n",
    "    df_feat_all.drop_duplicates(subset = ['adid','is_mobile','source_id'], inplace=True)\n",
    "    \n",
    "    # drop off duplicates catalog_item_id, seller_id\n",
    "    \n",
    "#     # read targets\n",
    "#     file = 'sem_l_'+date+'.csv'\n",
    "#     df_tmp = pd.read_csv(file, index_col=0)\n",
    "#     df_feat_all = df_tmp.merge(df_feat_all, left_on = 'catalog_item_id', right_on = 'catalog_item_id', how='left')\n",
    "    \n",
    "    # read sem coop features\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'semcoop' in x]\n",
    "    \n",
    "    # left join to ensure item coverage is based on target coverage\n",
    "    for file in files_to_read:\n",
    "        print('merge sem coop features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['adid','is_mobile','source_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id', 'source_id', 'adid', 'is_mobile'], how='left')\n",
    "        del df_tmp\n",
    "        \n",
    "    # read catalog feature\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'catalog' in x]\n",
    "    for file in files_to_read:\n",
    "        print('merge catalog features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['catalog_item_id','seller_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id'], how='left')\n",
    "        del df_tmp\n",
    "        \n",
    "    # read site features\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'site' in x]\n",
    "    for file in files_to_read:\n",
    "        print('merge site features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['catalog_item_id','seller_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id'], how='left')\n",
    "        del df_tmp\n",
    "        \n",
    "    # read bounce features\n",
    "    files_to_read = [x for x in files if x[-14:-4] == date and 'bounce' in x]\n",
    "    for file in files_to_read:\n",
    "        print('merge bounce features')\n",
    "        df_tmp = pd.read_csv(file)\n",
    "        df_tmp = df_tmp[(~pd.isnull(df_tmp['catalog_item_id']))&(~pd.isnull(df_tmp['seller_id']))]\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('int')\n",
    "        df_tmp['catalog_item_id'] = df_tmp['catalog_item_id'].astype('str')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('int')\n",
    "        df_tmp['seller_id'] = df_tmp['seller_id'].astype('str')\n",
    "        df_tmp.drop_duplicates(subset = ['catalog_item_id','seller_id'], inplace=True)\n",
    "        df_feat_all = df_feat_all.merge(df_tmp, on=['catalog_item_id', 'seller_id'], how='left')\n",
    "        del df_tmp\n",
    "\n",
    "    upload_csv_to_cloud_storage(df_feat_all, gcp_directoty_full+'df_feat_all_coop_item_'+date+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
